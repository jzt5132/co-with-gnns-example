{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TestBed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show how to solve combinatorial optimization problems with physics-inspired graph neural networks, as outlined in M. J. A. Schuetz, J. K. Brubaker, H. G. Katzgraber, _Combinatorial Optimization with Physics-Inspired Graph Neural Networks_, [arXiv:2107.01188](https://arxiv.org/abs/2107.01188). \n",
    "Here we focus on the canonical maximum independent set (MIS) problem, but our approach can easily be extended to other combinatorial optimization problems. \n",
    "For the actual implementation of the graph neural network we use the open-source ```dgl``` library. \n",
    "\n",
    "Please note we have provided a `requirements.txt` file, which defines the environment required to run this code. Because some of the packages are not available on default OSX conda channels, we have also provided suggested channels to find them on. These can be distilled into a single line as such:\n",
    "\n",
    "> conda create -n \\<environment_name\\> python=3 --file requirements.txt -c conda-forge -c dglteam -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "from itertools import chain, islice, combinations\n",
    "from networkx.algorithms.approximation.clique import maximum_independent_set as mis\n",
    "from time import time\n",
    "\n",
    "# MacOS can have issues with MKL. For more details, see\n",
    "# https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use device: cpu, torch dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# # fix seed to ensure consistent results\n",
    "seed_value = 1\n",
    "random.seed(seed_value)        # seed python RNG\n",
    "np.random.seed(seed_value)     # seed global NumPy RNG\n",
    "torch.manual_seed(seed_value)  # seed torch RNG\n",
    "\n",
    "# Set GPU/CPU\n",
    "TORCH_DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "TORCH_DTYPE = torch.float32\n",
    "print(f'Will use device: {TORCH_DEVICE}, torch dtype: {TORCH_DTYPE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0 - Define utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load a few general utility functions from ```utils.py``` before defining some helper functions specific to the MIS problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_gnn, run_gnn_training, qubo_dict_to_torch, gen_combinations, loss_func, postprocess_gnn_maxcut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem-specific (MIS) utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to generate Q matrix for Maximum Independent Set problem (MIS)\n",
    "def gen_q_dict_maxcut(nx_G):\n",
    "    \"\"\"\n",
    "    Helper function to generate QUBO matrix for MIS as minimization problem.\n",
    "    \n",
    "    Input:\n",
    "        nx_G: graph as networkx graph object (assumed to be unweigthed)\n",
    "    Output:\n",
    "        Q_dic: QUBO as defaultdict\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize our Q matrix\n",
    "    Q_dic = defaultdict(int)\n",
    "\n",
    "    # Update Q matrix for every edge in the graph\n",
    "    # all off-diagonal terms get penalty\n",
    "    for (u, v) in nx_G.edges:\n",
    "        Q_dic[(u, v)] = 2\n",
    "        Q_dic[(u, u)] -= 1\n",
    "        Q_dic[(v, v)] -= 1\n",
    "        \n",
    "    return Q_dic\n",
    "\n",
    "\n",
    "# Run classical MIS solver (provided by NetworkX)\n",
    "def run_mis_solver(nx_graph):\n",
    "    \"\"\"\n",
    "    helper function to run traditional solver for MIS.\n",
    "    \n",
    "    Input:\n",
    "        nx_graph: networkx Graph object\n",
    "    Output:\n",
    "        ind_set_bitstring_nx: bitstring solution as list\n",
    "        ind_set_nx_size: size of independent set (int)\n",
    "        number_violations: number of violations of ind.set condition\n",
    "    \"\"\"\n",
    "    # compare with traditional solver\n",
    "    t_start = time()\n",
    "    ind_set_nx = mis(nx_graph)\n",
    "    t_solve = time() - t_start\n",
    "    ind_set_nx_size = len(ind_set_nx)\n",
    "\n",
    "    # get bitstring list\n",
    "    nx_bitstring = [1 if (node in ind_set_nx) else 0 for node in sorted(list(nx_graph.nodes))]\n",
    "    edge_set = set(list(nx_graph.edges))\n",
    "\n",
    "    # Updated to be able to handle larger scale\n",
    "    print('Calculating violations...')\n",
    "    # check for violations\n",
    "    number_violations = 0\n",
    "    for ind_set_chunk in gen_combinations(combinations(ind_set_nx, 2), 100000):\n",
    "        number_violations += len(set(ind_set_chunk).intersection(edge_set))\n",
    "\n",
    "    return nx_bitstring, ind_set_nx_size, number_violations, t_solve\n",
    "\n",
    "\n",
    "# Calculate results given bitstring and graph definition, includes check for violations\n",
    "def postprocess_gnn_mis(best_bitstring, nx_graph):\n",
    "    \"\"\"\n",
    "    helper function to postprocess MIS results\n",
    "\n",
    "    Input:\n",
    "        best_bitstring: bitstring as torch tensor\n",
    "    Output:\n",
    "        size_mis: Size of MIS (int)\n",
    "        ind_set: MIS (list of integers)\n",
    "        number_violations: number of violations of ind.set condition\n",
    "    \"\"\"\n",
    "\n",
    "    # get bitstring as list\n",
    "    bitstring_list = list(best_bitstring)\n",
    "\n",
    "    # compute cost\n",
    "    size_mis = sum(bitstring_list)\n",
    "\n",
    "    # get independent set\n",
    "    ind_set = set([node for node, entry in enumerate(bitstring_list) if entry == 1])\n",
    "    edge_set = set(list(nx_graph.edges))\n",
    "\n",
    "    print('Calculating violations...')\n",
    "    # check for violations\n",
    "    number_violations = 0\n",
    "    for ind_set_chunk in gen_combinations(combinations(ind_set, 2), 100000):\n",
    "        number_violations += len(set(ind_set_chunk).intersection(edge_set))\n",
    "\n",
    "    return size_mis, ind_set, number_violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph hypers\n",
    "n = 800\n",
    "d = 3\n",
    "p = None\n",
    "graph_type = 'reg'\n",
    "\n",
    "# NN learning hypers #\n",
    "number_epochs = int(1e5)\n",
    "learning_rate = 1e-4 # 0.00587 #0.0001 #0.00467\n",
    "PROB_THRESHOLD = 0.5\n",
    "\n",
    "# Early stopping to allow NN to train to near-completion\n",
    "tol = 1e-4          # loss must change by more than tol, or trigger\n",
    "patience = 1000    # number early stopping triggers before breaking loop\n",
    "\n",
    "# Problem size (e.g. graph size)\n",
    "n = 800\n",
    "\n",
    "# Establish dim_embedding and hidden_dim values\n",
    "dim_embedding = 369 # int(np.sqrt(n))    # e.g. 10\n",
    "hidden_dim = 5 # int(dim_embedding/2)  # e.g. 5\n",
    "\n",
    "URL = \"https://web.stanford.edu/~yyye/yyye/Gset/G14\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Generate random graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import read_data_from_url, convert_data_into_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expect number of nodes 800 and edges 4694\n",
      "Total number of nodes: 800\n",
      "Total number of edges: 4694\n"
     ]
    }
   ],
   "source": [
    "# Constructs a random d-regular or p-probabilistic graph\n",
    "nx_graph = convert_data_into_graph(read_data_from_url(URL))\n",
    "# get DGL graph from networkx graph, load onto device\n",
    "graph_dgl = dgl.from_networkx(nx_graph=nx_graph)\n",
    "graph_dgl = graph_dgl.to(TORCH_DEVICE)\n",
    "\n",
    "# Construct Q matrix for graph\n",
    "q_torch = qubo_dict_to_torch(nx_graph, gen_q_dict_maxcut(nx_graph), torch_dtype=TORCH_DTYPE, torch_device=TORCH_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize graph\n",
    "# pos = nx.kamada_kawai_layout(nx_graph)\n",
    "# nx.draw(nx_graph, pos, with_labels=True, node_color=[[.7, .7, .7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Set up optimizer/GNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish pytorch GNN + optimizer\n",
    "opt_params = {'lr': learning_rate}\n",
    "gnn_hypers = {\n",
    "    'dim_embedding': dim_embedding,\n",
    "    'hidden_dim': hidden_dim,\n",
    "    'dropout': 0.0,\n",
    "    'number_classes': 1,\n",
    "    'prob_threshold': PROB_THRESHOLD,\n",
    "    'number_epochs': number_epochs,\n",
    "    'tolerance': tol,\n",
    "    'patience': patience\n",
    "}\n",
    "\n",
    "net, embed, optimizer = get_gnn(n, gnn_hypers, opt_params, TORCH_DEVICE, TORCH_DTYPE)\n",
    "\n",
    "# For tracking hyperparameters in results object\n",
    "gnn_hypers.update(opt_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Run GNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GNN...\n",
      "Epoch: 0, Loss: -11.34882640838623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/dgl/backend/pytorch/tensor.py:445: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Loss: -1441.65625\n",
      "Epoch: 2000, Loss: -2263.81396484375\n",
      "Epoch: 3000, Loss: -2383.629638671875\n",
      "Epoch: 4000, Loss: -2403.10107421875\n",
      "Epoch: 5000, Loss: -2409.190673828125\n",
      "Epoch: 6000, Loss: -2411.661865234375\n",
      "Epoch: 7000, Loss: -2412.796630859375\n",
      "Epoch: 8000, Loss: -2413.361328125\n",
      "Epoch: 9000, Loss: -2413.655517578125\n",
      "Epoch: 10000, Loss: -2413.8076171875\n",
      "Epoch: 11000, Loss: -2413.895751953125\n",
      "Epoch: 12000, Loss: -2413.942626953125\n",
      "Epoch: 13000, Loss: -2413.969970703125\n",
      "Epoch: 14000, Loss: -2413.986328125\n",
      "Epoch: 15000, Loss: -2413.99560546875\n",
      "Epoch: 16000, Loss: -2413.99853515625\n",
      "Epoch: 17000, Loss: -2413.999755859375\n",
      "Epoch: 18000, Loss: -2414.0\n",
      "Stopping early on epoch 18545 (patience: 1000)\n",
      "GNN training (n=800) took 84.186\n",
      "GNN final continuous loss: -2414.0\n",
      "GNN best continuous loss: -2414.0\n"
     ]
    }
   ],
   "source": [
    "print('Running GNN...')\n",
    "gnn_start = time()\n",
    "\n",
    "_, epoch, final_bitstring, best_bitstring = run_gnn_training(\n",
    "    q_torch, graph_dgl, net, embed, optimizer, gnn_hypers['number_epochs'],\n",
    "    gnn_hypers['tolerance'], gnn_hypers['patience'], gnn_hypers['prob_threshold'])\n",
    "\n",
    "gnn_time = time() - gnn_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Post-process GNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max cuts by GNN is -2414 \n",
      "Took 84.396s, model training took 84.188s\n"
     ]
    }
   ],
   "source": [
    "final_loss = loss_func(final_bitstring.float(), q_torch)\n",
    "final_bitstring_str = ','.join([str(x) for x in final_bitstring])\n",
    "\n",
    "# Process bitstring reported by GNN\n",
    "max_cuts = postprocess_gnn_maxcut(best_bitstring, nx_graph)\n",
    "gnn_tot_time = time() - gnn_start\n",
    "\n",
    "print(f'Max cuts by GNN is {max_cuts} ')\n",
    "print(f'Took {round(gnn_tot_time, 3)}s, model training took {round(gnn_time, 3)}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - (optional) Compare to classical solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run solver\n",
    "# print(f'Running built-in MIS solver (n={n}).')\n",
    "# start = time()\n",
    "# ind_set_bitstring_nx, ind_set_nx_size, nx_number_violations, t_solve = run_mis_solver(nx_graph)\n",
    "# end = time()\n",
    "# runtime_sol = end - start\n",
    "# print(f'Independence number found by nx solver is {ind_set_nx_size} with {nx_number_violations} violations.')\n",
    "# print(f'MIS solver took {round(runtime_sol, 3)}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
